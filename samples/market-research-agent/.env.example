# ============================================
# LLM Provider Configuration
# ============================================
# Choose your LLM provider: openai or anthropic
LLM_PROVIDER=openai

# Local LLM Gateway (LiteLLM, Ollama, etc.)
# Set USE_LOCAL_GATEWAY=true to use your local gateway
USE_LOCAL_GATEWAY=true
LLM_BASE_URL=http://localhost:9090/v1

# OpenAI Configuration (not needed if using local gateway)
OPENAI_API_KEY=dummy-key
# OPENAI_MODEL=gpt-4o  # High quality, expensive
OPENAI_MODEL=gpt-4o-mini  # Recommended: Cost-effective, great performance
# OPENAI_MODEL=gpt-3.5-turbo  # Budget option: Cheapest, lower quality

# Anthropic Configuration (not needed if using local gateway)
ANTHROPIC_API_KEY=dummy-key
ANTHROPIC_MODEL=claude-3-opus-20240229
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_MAX_TOKENS=4000

# ============================================
# Search API Configuration
# ============================================
# Using Tavily for AI-optimized web search
SEARCH_PROVIDER=tavily
TAVILY_API_KEY=your_tavily_key_here

# Note: If TAVILY_API_KEY is empty, mock search results will be used automatically

# ============================================
# vLLora Observability
# ============================================
# vLLora provides built-in observability at http://localhost:3000
# All requests are automatically traced in the Debug tab
# No additional configuration needed!

# ============================================
# Agent Configuration
# ============================================
# Maximum number of agent iterations
MAX_AGENT_ITERATIONS=10

# Timeout for agent operations (seconds)
AGENT_TIMEOUT=300

# Enable caching for LLM responses
ENABLE_CACHING=true

# Enable parallel agent execution
ENABLE_PARALLEL_EXECUTION=true

# ============================================
# Application Settings
# ============================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Output directory for reports
OUTPUT_DIR=./outputs

# Enable rich console output
ENABLE_RICH_OUTPUT=true

# Save intermediate results
SAVE_INTERMEDIATE_RESULTS=true

# ============================================
# Rate Limiting & Cost Control
# ============================================
# Maximum API calls per minute
MAX_API_CALLS_PER_MINUTE=60

# Maximum cost per analysis (USD)
MAX_COST_PER_ANALYSIS=5.00

# Enable cost tracking
ENABLE_COST_TRACKING=true

# ============================================
# Development Settings
# ============================================
# Enable debug mode
DEBUG_MODE=false

# Mock external APIs (for testing without API keys)
MOCK_EXTERNAL_APIS=false

# Save all prompts and responses
SAVE_PROMPTS_RESPONSES=true
